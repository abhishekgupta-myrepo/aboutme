
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../../Abhishek/About%20me/" rel="prev"/>
<link href="../Job%20Description%20of%20a%20Prompt%20Engineer/" rel="next"/>
<link href="../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.0, mkdocs-material-9.5.21" name="generator"/>
<title>Generative AI with Large Language Models - Abhishek Gupta</title>
<link href="../../assets/stylesheets/main.66ac8b77.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../stylesheets/extra.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="preference" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#generative-ai-with-large-language-models">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Abhishek Gupta" class="md-header__button md-logo" data-md-component="logo" href="../.." title="Abhishek Gupta">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Abhishek Gupta
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Generative AI with Large Language Models
            
          </span>
</div>
</div>
</div>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<a aria-label="Share" class="md-search__icon md-icon" data-clipboard="" data-clipboard-text="" data-md-component="search-share" href="javascript:void(0)" tabindex="-1" title="Share">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"></path></svg>
</a>
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/abhishekgupta-myrepo/aboutme.git" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../..">
        
  
    
  
  Home

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Abhishek/About%20me/">
          
  
  Abhishek

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="./">
          
  
  Artificial Intelligence

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../CICD/Chapter-Containers%20and%20Kubernetes/About%20Docker/">
          
  
  CICD

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Cloud/Chapter-Azure/Azure/">
          
  
  Cloud

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Data%20Management/Chapter-Data%20Management/Snowflake%20versus%20Databricks/">
          
  
  Data Management

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Healthcare/Prior%20Authorization%20Interoperability%20CME%20Rule/">
          
  
  Healthcare

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../IT%20Architecture/Digital%20Signatures/">
          
  
  IT Architecture

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Leadership/10%20Key%20Qualities%20of%20a%20Successful%20Manager/">
          
  
  Leadership

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Software%20Tools/Git/">
          
  
  Software Tools

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Abhishek Gupta" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="Abhishek Gupta">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
    Abhishek Gupta
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/abhishekgupta-myrepo/aboutme.git" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../..">
<span class="md-ellipsis">
    Home
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
<span class="md-ellipsis">
    Abhishek
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            Abhishek
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Abhishek/About%20me/">
<span class="md-ellipsis">
    About me
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
<span class="md-ellipsis">
    Artificial Intelligence
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            Artificial Intelligence
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Generative AI with Large Language Models
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Generative AI with Large Language Models
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#what-pattern-is-similar-between-openai-chatgpt-and-tesla-model-3">
<span class="md-ellipsis">
      What pattern is similar between OpenAI: ChatGPT and Tesla Model 3
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#terms-used-in-large-language-models">
<span class="md-ellipsis">
      Terms used in Large Language Models
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#legacy-ai-work">
<span class="md-ellipsis">
      Legacy AI work
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#models-tuning">
<span class="md-ellipsis">
      Models Tuning
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#foundational-models">
<span class="md-ellipsis">
      Foundational Models
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#appropriateness-of-the-models">
<span class="md-ellipsis">
      Appropriateness of the models
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#model-training-challenges">
<span class="md-ellipsis">
      Model Training Challenges
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#scaling-laws-and-compute-optimal-performance">
<span class="md-ellipsis">
      Scaling laws and compute optimal performance
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#model-performance">
<span class="md-ellipsis">
      Model Performance
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#foundation-models-pricing-">
<span class="md-ellipsis">
      Foundation Models Pricing -
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reinforcement-learning-with-human-feedback">
<span class="md-ellipsis">
      Reinforcement Learning with Human Feedback
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Job%20Description%20of%20a%20Prompt%20Engineer/">
<span class="md-ellipsis">
    Job Description of a Prompt Engineer
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
<span class="md-ellipsis">
    CICD
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            CICD
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_4_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
<span class="md-ellipsis">
    Chapter Containers and Kubernetes
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_1">
<span class="md-nav__icon md-icon"></span>
            Chapter Containers and Kubernetes
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../CICD/Chapter-Containers%20and%20Kubernetes/About%20Docker/">
<span class="md-ellipsis">
    Docker Notes
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CICD/Chapter-Containers%20and%20Kubernetes/CI%20with%20Travis/">
<span class="md-ellipsis">
    Travis based Continuous Integration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CICD/Chapter-Containers%20and%20Kubernetes/Docker%20Compose/">
<span class="md-ellipsis">
    Docker Compose
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CICD/Chapter-Containers%20and%20Kubernetes/Docker-Commands/">
<span class="md-ellipsis">
    Docker Commands Cheat sheet
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CICD/Chapter-Containers%20and%20Kubernetes/Docker-Swarm/">
<span class="md-ellipsis">
    Introduction to Swarm
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CICD/Chapter-Containers%20and%20Kubernetes/Kubernetes/">
<span class="md-ellipsis">
    Simple Kubernetes Project
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../CICD/Chapter-Containers%20and%20Kubernetes/Simple%20Docker%20Project/">
<span class="md-ellipsis">
    Compile simple project in docker
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
<span class="md-ellipsis">
    Cloud
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_5_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_5">
<span class="md-nav__icon md-icon"></span>
            Cloud
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_5_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
<span class="md-ellipsis">
    Chapter Azure
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_5_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_5_1">
<span class="md-nav__icon md-icon"></span>
            Chapter Azure
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Cloud/Chapter-Azure/Azure/">
<span class="md-ellipsis">
    Azure
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
<span class="md-ellipsis">
    Data Management
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
            Data Management
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_6_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
<span class="md-ellipsis">
    Chapter Data Management
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_6_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_6_1">
<span class="md-nav__icon md-icon"></span>
            Chapter Data Management
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Data%20Management/Chapter-Data%20Management/Snowflake%20versus%20Databricks/">
<span class="md-ellipsis">
    Snowflake Vs. Databricks
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
<span class="md-ellipsis">
    Healthcare
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_7">
<span class="md-nav__icon md-icon"></span>
            Healthcare
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Healthcare/Prior%20Authorization%20Interoperability%20CME%20Rule/">
<span class="md-ellipsis">
    Prior Authorization Interoperability CME Rule
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
<span class="md-ellipsis">
    IT Architecture
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_8_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_8">
<span class="md-nav__icon md-icon"></span>
            IT Architecture
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../IT%20Architecture/Digital%20Signatures/">
<span class="md-ellipsis">
    Digital Signatures
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_9" type="checkbox"/>
<label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
<span class="md-ellipsis">
    Leadership
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_9_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_9">
<span class="md-nav__icon md-icon"></span>
            Leadership
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Leadership/10%20Key%20Qualities%20of%20a%20Successful%20Manager/">
<span class="md-ellipsis">
    10 Key Qualities of a Successful Manager
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_10" type="checkbox"/>
<label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
<span class="md-ellipsis">
    Software Tools
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_10_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_10">
<span class="md-nav__icon md-icon"></span>
            Software Tools
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Software%20Tools/Git/">
<span class="md-ellipsis">
    Git
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#what-pattern-is-similar-between-openai-chatgpt-and-tesla-model-3">
<span class="md-ellipsis">
      What pattern is similar between OpenAI: ChatGPT and Tesla Model 3
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#terms-used-in-large-language-models">
<span class="md-ellipsis">
      Terms used in Large Language Models
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#legacy-ai-work">
<span class="md-ellipsis">
      Legacy AI work
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#models-tuning">
<span class="md-ellipsis">
      Models Tuning
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#foundational-models">
<span class="md-ellipsis">
      Foundational Models
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#appropriateness-of-the-models">
<span class="md-ellipsis">
      Appropriateness of the models
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#model-training-challenges">
<span class="md-ellipsis">
      Model Training Challenges
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#scaling-laws-and-compute-optimal-performance">
<span class="md-ellipsis">
      Scaling laws and compute optimal performance
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#model-performance">
<span class="md-ellipsis">
      Model Performance
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#foundation-models-pricing-">
<span class="md-ellipsis">
      Foundation Models Pricing -
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reinforcement-learning-with-human-feedback">
<span class="md-ellipsis">
      Reinforcement Learning with Human Feedback
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<div><h1 id="generative-ai-with-large-language-models">Generative AI with Large Language Models<a class="headerlink" href="#generative-ai-with-large-language-models" title="Permanent link">¶</a></h1>
<h2 id="what-pattern-is-similar-between-openai-chatgpt-and-tesla-model-3">What pattern is similar between OpenAI: ChatGPT and Tesla Model 3<a class="headerlink" href="#what-pattern-is-similar-between-openai-chatgpt-and-tesla-model-3" title="Permanent link">¶</a></h2>
<p>The underlying technology in both was thrust into public consciousness only after the release of these products, although the technology (Transformers in case of ChatGPT: Electric motor for cars in case of Model 3) existed for many years earlier.</p>
<ul>
<li>Generative AI with LLMs is a general purpose technology that can be applied to many use cases. This is a new technology with a lot of work to be done in the area. Just like deep learning that originated 15 years back, it has huge growth potential.</li>
</ul>
<h2 id="terms-used-in-large-language-models">Terms used in Large Language Models<a class="headerlink" href="#terms-used-in-large-language-models" title="Permanent link">¶</a></h2>
<ul>
<li>Training generative AI models differs from conventional models as it involves prompts and completion, known as inference.</li>
<li>Prompts usually consist of context windows with 1000 words or fewer. However, there are models from Anthropic that provide very large context windows.</li>
<li>Completion refers to the model's output, which predicts the next word based on the input, and this process is called inference.</li>
<li>In the context of context learning, where the desired model output is provided as part of the prompt, there are three key ways to approach it:<ul>
<li>Zero-shot inference: In this approach, no specific examples of the desired output are given to the model.</li>
<li>One-shot inference: Here, the model is directed on what to do and provided with an example of the desired output. This increases the chances of accurate output generation, even with smaller models.</li>
<li>Few-shot inference: Multiple examples with different scenarios are included, assisting in generating output even with smaller models.</li>
</ul>
</li>
<li>Prompts play a vital role in generating the desired output. Larger-sized models excel at zero-shot inference, while smaller models are efficient for a narrower set of tasks.</li>
<li>However, it's crucial to consider the context window, which limits the amount of data that can be used as a prompt.</li>
<li>To enhance performance, fine-tuning can be employed by providing additional data, allowing the model to learn more effectively.</li>
</ul>
<h2 id="legacy-ai-work">Legacy AI work<a class="headerlink" href="#legacy-ai-work" title="Permanent link">¶</a></h2>
<ul>
<li>RNN (Recurrent Neural Network) is a type of neural network that handles sequential data by introducing feedback loops. These loops allow RNNs to maintain a hidden state, capturing context over time. They are used in tasks like language translation, speech recognition, and more. Variants like LSTM and GRU address long-term dependency issues, making RNNs effective for modeling sequential data.</li>
<li>Word2Vec is an NLP technique that creates word embeddings, converting words into meaningful numerical vectors. It represents words in a continuous vector space, capturing semantic relationships between words. These embeddings are widely used in various NLP tasks to enhance models' understanding of text and improve performance.</li>
</ul>
<h2 id="models-tuning">Models Tuning<a class="headerlink" href="#models-tuning" title="Permanent link">¶</a></h2>
<ul>
<li>the inference parameters of the model can be used to control the output behavior od the model and the inference it is making from the prompt. This is different from teh training pratamers.<ul>
<li>max tokens - number of tokens that are generaed. It is the max of new toekns. It can very well happen that hte end of sequence is reached before the hard limit is reached.</li>
<li>Greedy decoding - short generation - repeated sequence of words, natural output and more general - use the random sampling. In this case the model will choose the word based on teh randow weighted distribution. but in case of the random smapling is uncontrolled there is a risk of the model wnadering off to different words or topics.</li>
<li>Hugging face - requires explicit selection of the sampling method. And will need you to explicitly disable the random sampling using the flag.</li>
<li>This is contrilled using top K - more reasonable and makes more sense where the model restricts the weighted random sampling to the top k words only. Ensures some variability.</li>
<li>Top p - is the number of samples whose some of the probabilities some up to be less than equal to &lt;=p</li>
<li>Temperature - shape of the model probability distribution . This is applied at the final layer of the softmax function and controls the distribution of the probabilities. Lower temperatures &lt; 1 will result in strongly peaked distrbution resulting in odd favouring few words and therfore the output prediction will be less random. The hotter temperatures &gt; 1 will result in broader, flatter distribution this will result in some degree of randomess in the predicted word output duringt the random sampling. This will lead to more creative output.</li>
<li>softmax will be used as default if the temp = 1 .</li>
</ul>
</li>
</ul>
<h2 id="foundational-models">Foundational Models<a class="headerlink" href="#foundational-models" title="Permanent link">¶</a></h2>
<ul>
<li>These foundational models comprise billions of parameters. Parameters are kind of the memory of the model. Larger the model the more sophisticated model becomes.</li>
<li>The larger the model the more subjectiveness and understanding of the model is achieved that helps it to reason better. but it is not always true. for smaller and specific tasks smaller models tend to perform equally well by doing fine tuning.</li>
<li><a href="https://lifearchitect.ai/timeline/">Timeline of AI and language models – Dr Alan D. Thompson – Life Architect</a></li>
<li>Hugging Face</li>
<li>BERT - 110M</li>
<li>GPT</li>
<li>FLAN-T5</li>
<li>LLaMa</li>
<li>PaLM</li>
<li>BLOOM - 176B</li>
</ul>
<h2 id="appropriateness-of-the-models">Appropriateness of the models<a class="headerlink" href="#appropriateness-of-the-models" title="Permanent link">¶</a></h2>
<ul>
<li>It's not necessary to use the large parameter for every use case. Some single application use cases work well with smaller models. Therefore, with so many foundational models that are available it is important for the developers to learn which model will work the best and in which scenario it is best to build a new model vs. in which case fine-tuning existing model will make more sense.</li>
<li>Pre-training the model from scratch  - self - supervised learning - model learns the pattern from the language that has been fed into it and the trains itself based on the objective function to minimize. The model is also dependent upon the architecture it selects.</li>
<li>create embeddings / vector representations</li>
<li>The encoder models  / auto-encoder models - objective is reconstruct text("denoising") it is training using masked language modeling (MLM)  - build bi-directional understanding of the sequence. sentence level tasks such as sentence classification, sentiment, token level tasks - name entity recognition or word classification - BERT, ROBERT</li>
<li>De-coder only models - auto-regressive models - uses causal language modeling (CLM) where the model tasks is to predict the next word. These are used in text generation and other general tasks - GPT , BLOOM. Show zero-shot inference capabilities.</li>
<li>Encoder/Decoder models - sequence-to-sequence models - example - T5  and BART. uses span correction. This is useful in text summarization, translation, question answering. the sentences of variable length are masked and are then replaced with a snetinel token that does not belong to the dictionary and then uses the auto-regressive model to predict the next word to reconstruct the sentinel token.</li>
<li>Some of the pre-trained models it has been observed that the larger the model the better it is at performing the general task. This has led to the growth of larger models. This has been fueled by the <ul>
<li>availability of the transformer architecture that is highly scalable</li>
<li>available of the data</li>
<li>availability of the compute resources to train the mode. </li>
</ul>
</li>
<li>Training these large model is super expensive and at a given point in time it becomes infeasible to train such models further.</li>
</ul>
<h2 id="model-training-challenges">Model Training Challenges<a class="headerlink" href="#model-training-challenges" title="Permanent link">¶</a></h2>
<ul>
<li>CUDA - Compute unified Device Architecture - CUDA out of memory - this is often recieved when using Nvidia GPUs for training or loading the models.</li>
<li>Nvidia A100  - GPU models, 80GB ram is the max</li>
<li>1B param model @32bit precision requires 80GB memory, @16bit require 40GB of memory, and @8bit require require 20GB of memory. so to fit the model you should use 16bit or 8 bit quantization.</li>
<li>Quantization - FP32 --&gt; FP16 or BFLOT16 ( google , hybrid, supported by nvidia)</li>
<li>![[Pasted image 20230717230341.png]]</li>
</ul>
<p>![[Pasted image 20230718223826.png]]</p>
<p>![[Pasted image 20230718223842.png]]</p>
<ul>
<li>FSDP - ZeRO - Sharding based approach - MS paper</li>
<li>Full Replication</li>
<li>DDP - Distribute data parallel</li>
<li>Full sharding</li>
<li>Hybrid Sharding - beyong </li>
<li>beyond 2.8B parameters DDP and full replication does not work.</li>
</ul>
<h2 id="scaling-laws-and-compute-optimal-performance">Scaling laws and compute optimal performance<a class="headerlink" href="#scaling-laws-and-compute-optimal-performance" title="Permanent link">¶</a></h2>
<ul>
<li>kaplan - 2020 - scaling laws for neural language models</li>
<li>Chinchilla paper - 2022 - training compute optimal large language model
![[Pasted image 20230718225304.png]]</li>
<li>Metric to measure the compute budget required - <ul>
<li>1 petaflop/S-days - floating point operations performed at the rate of 1 petaflop per second for 1 day. = 8 Nvidia V100s GPUs or 2 Nvidia A100 GPUs at 100% efficiency.
![[Pasted image 20230718230906.png]]
<a href="https://arxiv.org/abs/2303.17564">[2303.17564] BloombergGPT: A Large Language Model for Finance (arxiv.org)</a></li>
</ul>
</li>
</ul>
<h2 id="model-performance">Model Performance<a class="headerlink" href="#model-performance" title="Permanent link">¶</a></h2>
<p><a href="https://towardsdatascience.com/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b">Foundations of NLP Explained — Bleu Score and WER Metrics | by Ketan Doshi | Towards Data Science</a></p>
<h2 id="foundation-models-pricing-">Foundation Models Pricing -<a class="headerlink" href="#foundation-models-pricing-" title="Permanent link">¶</a></h2>
<ul>
<li>OpenAI - Foundational models pricing - <a href="https://openai.com/pricing">Pricing (openai.com)</a><ul>
<li>Tokens , Input/Output, Context Window</li>
</ul>
</li>
<li>
</li></ul>
<h2 id="reinforcement-learning-with-human-feedback">Reinforcement Learning with Human Feedback<a class="headerlink" href="#reinforcement-learning-with-human-feedback" title="Permanent link">¶</a></h2>
<p><a href="https://openai.com/research/learning-from-human-preferences">Learning from human preferences (openai.com)</a>
- Using RL to provide human cues to the agent to learn the behaviour and quickly take feedback from the humans to optimize its goal function.
- This has perils to it as well where the agent tries to trick the human by modofying its policies.</p>
<h1 id="generative-ai-project-lifecycle">Generative AI Project Lifecycle<a class="headerlink" href="#generative-ai-project-lifecycle" title="Permanent link">¶</a></h1>
<p><a href="https://dr-arsanjani.medium.com/the-generative-ai-life-cycle-fb2271a70349">The Generative AI Life-cycle. The common AI/ML Lifecycle consists of… | by Ali Arsanjani | Medium</a>
![[Pasted image 20230714052407.png]]</p>
<h2 id="challenges-risks-and-limitations">Challenges, Risks, and Limitations<a class="headerlink" href="#challenges-risks-and-limitations" title="Permanent link">¶</a></h2>
<ul>
<li>Uable to perform complex mathematical computations</li>
<li>provide inaccurate information - Hallucination</li>
<li>
</li></ul>
<h2 id="transformers">Transformers<a class="headerlink" href="#transformers" title="Permanent link">¶</a></h2>
<h2 id="-the-transformers-architecture-was-proposed-in-a-paper-published-in-2017-by-google-attention-is-all-you-need-170603762pdf-arxivorg">- The transformers' architecture was proposed in a paper published in 2017 by google 'attention is all you need'  <a href="https://arxiv.org/pdf/1706.03762.pdf">1706.03762.pdf (arxiv.org)</a><a class="headerlink" href="#-the-transformers-architecture-was-proposed-in-a-paper-published-in-2017-by-google-attention-is-all-you-need-170603762pdf-arxivorg" title="Permanent link">¶</a></h2>
<ul>
<li>Prior to this existing models such as RNN, LSTM, CNN has the problem of the context understanding if the word was not close.</li>
<li>Multi-headed self attention – 12-100 self attention heads. each head is initialized randomly with different weighs. Each head learns different about the word. you cannot control which head focuses on what aspect of the language.</li>
<li>Token embedding and position embeddings is used in the transformers that derives its implementation from the word embeddings that were implemented in the word2Vec algorithms.</li>
<li>Transformers generally uses vectors of size 512
<img alt="300" src="TransformerArchitecture.png"/></li>
<li>Simplified transformer architecuture.</li>
</ul>
<p><img alt="200" src="SimpleTransformerArchitecture.png"/></p>
<ul>
<li>
<p>there are various combinations that are possible around this architecture - 
![[Pasted image 20230712224342.png]]</p>
</li>
<li>
<p>Encoder only models - BERT - used for classification tasks. input and output of the same length. The use is less common these days. add additionaly layers to the transformer - sentiment analysis.</p>
</li>
<li>Encoder-Decoder -- sequeunce to sequence input of a given length and output of variable lenght  - T5, general text generation, BART, and T5. translation.</li>
<li>Decoder only - most common- these are generalized to most tasks. GPT , BLOOM, Jurassic, LAMA ..</li>
<li>The open </li>
</ul>
<h2 id="generative-ai-modalities">Generative AI Modalities<a class="headerlink" href="#generative-ai-modalities" title="Permanent link">¶</a></h2>
<ul>
<li>Chats - All the text associated tasks are associated with next word prediction concept.<ul>
<li>Translation</li>
<li>Text summarization</li>
<li>perform actions such as - meeting minutes, write email</li>
<li>Language to code</li>
<li>Entity extraction - smaller focussed tasks - kind of word classification</li>
<li>Augmenting LLM with external APIs that are invoked by LLM for real time data fetch from other databases.</li>
<li>
</li></ul>
</li>
<li>Text to image</li>
<li>Text to code</li>
</ul>
<p>![[Pasted image 20230714051056.png]]</p>
<hr/>
<h2 id="references-"><strong>References -</strong><a class="headerlink" href="#references-" title="Permanent link">¶</a></h2>
<ul>
<li><a href="https://www.coursera.org/learn/generative-ai-with-llms/home/week/1"><strong>Coursera Course</strong></a>): Generative AI with Large Language Models by Deeplearning.ai in partnership with AWS</li>
<li>
<h3 id="transformer-architecture"><strong>Transformer Architecture</strong><a class="headerlink" href="#transformer-architecture" title="Permanent link">¶</a></h3>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1706.03762"><strong>Attention is All You Need</strong></a> - This paper introduced the Transformer architecture, with the core “self-attention” mechanism. This article was the foundation for LLMs.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2211.05100"><strong>BLOOM: BigScience 176B Model</strong></a> - BLOOM is a open-source LLM with 176B parameters (similar to GPT-4) trained in an open and transparent way. In this paper, the authors present a detailed discussion of the dataset and process used to train the model. You can also see a high-level overview of the model <a href="https://bigscience.notion.site/BLOOM-BigScience-176B-Model-ad073ca07cdf479398d5f95d88e218c4">here</a>.</p>
</li>
<li>
<p><a href="https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/week/3"><strong>Vector Space Models</strong></a> - Series of lessons from DeepLearning.AI's Natural Language Processing specialization discussing the basics of vector space models and their use in language modeling.</p>
</li>
</ul>
<h3 id="pre-training-and-scaling-laws"><strong>Pre-training and scaling laws</strong><a class="headerlink" href="#pre-training-and-scaling-laws" title="Permanent link">¶</a></h3>
<ul>
<li><a href="https://arxiv.org/abs/2001.08361"><strong>Scaling Laws for Neural Language Models</strong></a> - empirical study by researchers at OpenAI exploring the scaling laws for large language models.</li>
</ul>
<h3 id="model-architectures-and-pre-training-objectives"><strong>Model architectures and pre-training objectives</strong><a class="headerlink" href="#model-architectures-and-pre-training-objectives" title="Permanent link">¶</a></h3>
<ul>
<li>
<p><a href="https://arxiv.org/pdf/2204.05832.pdf"><strong>What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?</strong></a> - The paper examines modeling choices in large pre-trained language models and identifies the optimal approach for zero-shot generalization.</p>
</li>
<li>
<p><a href="https://huggingface.co/tasks"><strong>HuggingFace Tasks</strong></a> <strong>and</strong> <a href="https://huggingface.co/models"><strong>Model Hub</strong></a> - Collection of resources to tackle varying machine learning tasks using the HuggingFace library.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2302.13971.pdf"><strong>LLaMA: Open and Efficient Foundation Language Models</strong></a> - Article from Meta AI proposing Efficient LLMs (their model with 13B parameters outperform GPT3 with 175B parameters on most benchmarks)</p>
</li>
</ul>
<h3 id="scaling-laws-and-compute-optimal-models"><strong>Scaling laws and compute-optimal models</strong><a class="headerlink" href="#scaling-laws-and-compute-optimal-models" title="Permanent link">¶</a></h3>
<ul>
<li>
<p><a href="https://arxiv.org/pdf/2005.14165.pdf"><strong>Language Models are Few-Shot Learners</strong></a> - This paper investigates the potential of few-shot learning in Large Language Models.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2203.15556.pdf"><strong>Training Compute-Optimal Large Language Models</strong></a> - Study from DeepMind to evaluate the optimal model size and number of tokens for training LLMs. Also known as “Chinchilla Paper”.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2303.17564.pdf"><strong>BloombergGPT: A Large Language Model for Finance</strong></a> - LLM trained specifically for the finance domain, a good example that tried to follow chinchilla laws.</p>
</li>
</ul>
<h2 id="multi-task-instruction-fine-tuning"><strong>Multi-task, instruction fine-tuning</strong><a class="headerlink" href="#multi-task-instruction-fine-tuning" title="Permanent link">¶</a></h2>
<ul>
<li>
<p><a href="https://arxiv.org/pdf/2210.11416.pdf"><strong>Scaling Instruction-Finetuned Language Models</strong></a> - Scaling fine-tuning with a focus on task, model size and chain-of-thought data.</p>
</li>
<li>
<p><a href="https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html"><strong>Introducing FLAN: More generalizable Language Models with Instruction Fine-Tuning</strong></a> - This blog (and article) explores instruction fine-tuning, which aims to make language models better at performing NLP tasks with zero-shot inference.</p>
</li>
</ul>
<h2 id="model-evaluation-metrics"><strong>Model Evaluation Metrics</strong><a class="headerlink" href="#model-evaluation-metrics" title="Permanent link">¶</a></h2>
<ul>
<li>
<p><a href="https://crfm.stanford.edu/helm/latest/"><strong>HELM - Holistic Evaluation of Language Models</strong></a> - HELM is a living benchmark to evaluate Language Models more transparently.</p>
</li>
<li>
<p><a href="https://openreview.net/pdf?id=rJ4km2R5t7"><strong>General Language Understanding Evaluation (GLUE) benchmark</strong></a> - This paper introduces GLUE, a benchmark for evaluating models on diverse natural language understanding (NLU) tasks and emphasizing the importance of improved general NLU systems.</p>
</li>
<li>
<p><a href="https://super.gluebenchmark.com/"><strong>SuperGLUE</strong></a> - This paper introduces SuperGLUE, a benchmark designed to evaluate the performance of various NLP models on a range of challenging language understanding tasks.</p>
</li>
<li>
<p><a href="https://aclanthology.org/W04-1013.pdf"><strong>ROUGE: A Package for Automatic Evaluation of Summaries</strong></a> - This paper introduces and evaluates four different measures (ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S) in the ROUGE summarization evaluation package, which assess the quality of summaries by comparing them to ideal human-generated summaries.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2009.03300.pdf"><strong>Measuring Massive Multitask Language Understanding (MMLU)</strong></a> - This paper presents a new test to measure multitask accuracy in text models, highlighting the need for substantial improvements in achieving expert-level accuracy and addressing lopsided performance and low accuracy on socially important subjects.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2206.04615.pdf"><strong>BigBench-Hard - Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models</strong></a> - The paper introduces BIG-bench, a benchmark for evaluating language models on challenging tasks, providing insights on scale, calibration, and social bias.</p>
</li>
</ul>
<h2 id="parameter-efficient-fine-tuning-peft"><strong>Parameter- efficient fine tuning (PEFT)</strong><a class="headerlink" href="#parameter-efficient-fine-tuning-peft" title="Permanent link">¶</a></h2>
<ul>
<li>
<p><a href="https://arxiv.org/pdf/2303.15647.pdf"><strong>Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning</strong></a> - This paper provides a systematic overview of Parameter-Efficient Fine-tuning (PEFT) Methods in all three categories discussed in the lecture videos.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2211.15583.pdf"><strong>On the Effectiveness of Parameter-Efficient Fine-Tuning</strong></a> - The paper analyzes sparse fine-tuning methods for pre-trained models in NLP.</p>
</li>
</ul>
<h2 id="lora"><strong>LoRA</strong><a class="headerlink" href="#lora" title="Permanent link">¶</a></h2>
<ul>
<li>
<p><a href="https://arxiv.org/pdf/2106.09685.pdf"><strong>LoRA Low-Rank Adaptation of Large Language Models</strong></a> - This paper proposes a parameter-efficient fine-tuning method that makes use of low-rank decomposition matrices to reduce the number of trainable parameters needed for fine-tuning language models.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2305.14314.pdf"><strong>QLoRA: Efficient Finetuning of Quantized LLMs</strong></a> - This paper introduces an efficient method for fine-tuning large language models on a single GPU, based on quantization, achieving impressive results on benchmark tests.</p>
</li>
</ul>
<h2 id="prompt-tuning-with-soft-prompts"><strong>Prompt tuning with soft prompts</strong><a class="headerlink" href="#prompt-tuning-with-soft-prompts" title="Permanent link">¶</a></h2>
<ul>
<li><a href="https://arxiv.org/pdf/2104.08691.pdf"><strong>The Power of Scale for Parameter-Efficient Prompt Tuning</strong></a> - The paper explores "prompt tuning," a method for conditioning language models with learned soft prompts, achieving competitive performance compared to full fine-tuning and enabling model reuse for many tasks.</li>
</ul></div>
<aside class="md-source-file">
<span class="md-source-file__fact">
<span class="md-icon" title="Last update">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">May 18, 2024</span>
</span>
</aside>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Copyright © 2024 abhishekgupta
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["navigation.top", "navigation.tabs", "navigation.expand", "search.share", "content.tabs.link"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../assets/javascripts/bundle.a7c05c9e.min.js"></script>
<script src="../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
<script src="../../javascript/insights.js"></script>
</body>
</html>